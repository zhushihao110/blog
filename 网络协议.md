# 网络协议

### OSI模型

7	应用层	例如HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS、RTSP、XMPP、Whois、ENRP
6	表示层	例如XDR、ASN.1、SMB、AFP、NCP
5	会话层	例如ASAP、TLS、SSH、ISO 8327 / CCITT X.225、RPC、NetBIOS、ASP、Winsock、BSD sockets
4	传输层	例如TCP、UDP、RTP、SCTP、SPX、ATP、IL
3	网络层	例如IP、ICMP、IGMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP、ARP、RARP、 X.25
2	数据链路层	例如以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11、FDDI、PPP
1	物理层	例如线路、无线电、光纤

###  [TCP 三次握手以及四次挥手的流程。为什么需要三次握手以及四次挥手](https://zhuanlan.zhihu.com/p/53374516)

**3次握手的作用就是双方都能明确自己和对方的收、发能力是正常的**

- 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：**客户端的发送能力、服务端的接收能力是正常的**
- 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：**服务端的接收、发送能力，客户端的接收、发送能力是正常的**。 从客户端的视角来看，我接到了服务端发送过来的响应数据包，说明服务端接收到了我在第一次握手时发送的网络包，并且成功发送了响应数据包，这就说明，服务端的接收、发送能力正常。而另一方面，我收到了服务端的响应数据包，说明我第一次发送的网络包成功到达服务端，这样，我自己的发送和接收能力也是正常的
- 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：**客户端的接收、发送能力，服务端的发送、接收能力是正常的**。 第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。而在第三次握手时，服务端收到了客户端对第二次握手作的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接收到了。所以，我的发送能力是正常的。而客户端的接收能力也是正常的

**四次挥手：TCP连接是双向传输的对等的模式，就是说双方都可以同时向对方发送或接收数据**

- 当有一方要关闭连接时，会发送指令FIN报文告知对方，我要关闭连接了。
- 这时对方会回一个ACK，此时一个方向的连接关闭。
- 但是另一个方向仍然可以继续传输数据，等到发送完了所有的数据后，会发送一个FIN段来关闭此方向上的连接。
- 接收方发送ACK确认关闭连接。

**注意，接收到FIN报文的一方只能回复一个ACK, 它是无法马上返回对方一个FIN报文段的，因为结束数据传输的“指令”是上层应用层给出的，我只是一个“搬运工”，我无法了解`“上层的意志”`**

------

### HTTP 与  HTTPS  有哪些区别， HTTPS 的加密与认证过程

- https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
- http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
- http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
- http的连接很简单，是无状态的；HTTPS协议是由SSL/TSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

HTTPS加密过程：

- 客户使用https的URL访问Web服务器，要求与Web服务器建立SSL/TSL连接。
- Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。
- 客户端的浏览器与Web服务器开始**协商SSL/TSL连接的安全等级**，也就是信息加密的等级。
- 客户端的浏览器根据双方同意的安全等级，**建立会话密钥**，然后利用网站的公钥将会话密钥加密，并传送给网站。
- Web服务器利用自己的私钥解密出会话密钥。
- Web服务器利用会话密钥加密与客户端之间的通信

协商SSL/TSL连接的安全等级：选择加密算法（对称或非对称加密算法）

- 对称加密算法：加密与解密使用同一种算法
- 非对称加密算法：加密与加密使用不同的算法
- 加密算法本质是数学运算，复杂度越高越安全，同时运算量也更大

------

### TCP 与 UDP 在网络协议中的哪一层，他们之间有什么区别

**TCP协议属于第四层传输层，是一种面向连接的、可靠的、基于字节流的传输层通信协议**：

- 基于字节流的方式
- 面向连接
- 可靠的通信方式
- 在网络状况不佳的时候，尽量降低系统由于重传带来的带宽开销
- 通信连接维护是面向通信的两个端点的，而不考虑中间网段和节点

**UDP协议是无连接的传输层协议，提供面向事务的简单、不可靠的信息传送服务**

- UDP是一个无连接协议，传输数据之前源端和终端不建立连接
- 吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、源端和终端主机性能的限制
- UDP信息包的标题很短，只有8个字节，相对于TCP的20个字节信息包而言UDP的额外开销很小
- UDP是面向报文的

**区别**：

- TCP面向连接，UDP是无连接的，即发送数据之前不需要建立连接
- UDP具有较好的实时性，工作效率比TCP高，适用于对高速传输和实时性有较高的通信或广播通信
- 每一条TCP连接只能是点到点的；UDP支持一对一、一对多、多对一和多对多的交互通信
- TCP对系统资源要求较多，UDP对系统资源要求较少
- TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP尽最大努力交付，即不保证可靠交付。TCP通过校验和，重传控制，序号标识，滑动窗口、确认应答实现可靠传输。如丢包时的重发控制，还可以对次序乱掉的分包进行顺序控制

------

### TCP [怎么保证可靠传输](https://www.cnblogs.com/xiaolincoding/p/12732052.html)

- 确认和重传：接收方收到报文就会确认(ACK)，发送方发送一段时间后没有收到确认就重传。
- 数据校验：TCP报文头有校验和，用于校验报文是否损坏
- 数据合理分片和排序：tcp会按MTU（最大传输单元）合理分片，接收方会缓存未按序到达的数据，重新排序后再交给应用层。
- 流量控制（滑动窗口）：当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。
- 拥塞控制：当网络拥塞时，减少数据的发送

------

### TCP [滑动窗口以及重传机制](https://www.cnblogs.com/xiaolincoding/p/12732052.html)

滑动窗口：TCP数据包的头部有一个window字段，它主要是用来告诉对方自己能接收多大的数据（注意只有TCP包中的数据部分占用这个空间），这个字段在通信双方建立连接时协商确定，并且在通信过程中不断更新，故取名为滑动窗口，有了这个字段，数据发送方就知道自己该不该发送数据，以及该发多少数据了。TCP协议的流量控制正是通过滑动窗口实现，从而保证通信双方的接收缓冲区不会溢出，数据不会丢失。

窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**

窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除

重传机制：是通过序列号与确认应答

- 超时重传：超过一定时间没有返回ACK，则重传
- 快速重传：快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段
- SACK：**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。
- D-SACK： **使用了 SACK 来告诉「发送方」有哪些数据被重复接收了**

------

### TCP 中常见的拥塞控制算法有哪些

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**

- 慢启动：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1，慢启动门限`ssthresh`，当 `cwnd` < `ssthresh` 时，使用慢启动算法，当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」
- 拥塞避免： 每当收到一个 ACK 时，cwnd 增加 1/cwnd
- 拥塞发生：当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种
     - 当发生了「超时重传」，则就会使用拥塞发生算法：ssthresh` 设为 `cwnd/2，cwnd重置为1
     - 发生快速重传的拥塞发生算法：cwnd = cwnd/2也就是设置为原来的一半，ssthresh = cwnd，进入快速恢复算法
- 快速恢复：快速重传和快速恢复算法一般同时使用
    - 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
    - 重传丢失的数据包；
    - 如果再收到重复的 ACK，那么 cwnd 增加 1；
    - 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态

------

### 什么是 TCP 粘包和拆包

当我们发送两个完整包到接收端的时候：

![img](https://user-gold-cdn.xitu.io/2018/8/6/1650c8b818595eef?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

正常情况会接收到两个完整的报文

但也有以下的情况：

![img](https://user-gold-cdn.xitu.io/2018/8/6/1650c8b818748287?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

接收到的是一个报文，它是由发送的两个报文组成的，这样对于应用程序来说就很难处理了（这样称为粘包）。

![img](https://user-gold-cdn.xitu.io/2018/8/6/1650c8b818743825?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

还有可能出现上面这样的虽然收到了两个包，但是里面的内容却是互相包含，对于应用来说依然无法解析（拆包）

对于这样的问题只能通过上层的应用来解决，常见的方式有：

- 在报文末尾增加换行符表明一条完整的消息，这样在接收端可以根据这个换行符来判断消息是否完整。
- 将消息分为消息头、消息体。可以在消息头中声明消息的长度，根据这个长度来获取报文（比如 808 协议）
- 规定好报文长度，不足的空位补齐，取的时候按照长度截取即可。

------

### TCP 的 keepalive 和 HTTP 的 keepalive 的区别

TCP 的 keepalive：

- TCP如果在一段时间（**保活时间：tcp_keepalive_time**）内此连接都不活跃，开启保活功能的一端会向对端发送一个保活探测报文。

- 若对端正常存活，且连接有效，对端必然能收到探测报文并进行响应。此时，发送端收到响应报文则证明TCP连接正常，重置保活时间计数器即可。
- 若由于网络原因或其他原因导致，发送端无法正常收到保活探测报文的响应。那么在一定**探测时间间隔（tcp_keepalive_intvl）**后，将继续发送保活探测报文。直到收到对端的响应，或者达到配置的**探测循环次数上限（tcp_keepalive_probes）**都没有收到对端响应，这时对端会被认为不可达，TCP连接随存在但已失效，需要将连接做中断处理

三个参数**保活时间：tcp_keepalive_time、探测时间间隔：tcp_keepalive_intvl、探测循环次数：tcp_keepalive_probes**

![](C:\Users\v_shihaozhu\Desktop\新建文件夹\tcp-keepalive.png)

HTTP 的 keepalive：

- http1.0默认是关闭的，通过http请求头设置“connection: keep-alive”进行开启；http1.1中默认开启，通过http请求头设置“connection: close”关闭
- 若开启后，在一次http请求中，服务器进行响应后，不再直接断开TCP连接，而是将TCP连接维持一段时间。在这段时间内，如果同一客户端再次向服务端发起http请求，便可以复用此TCP连接，向服务端发起请求，并重置timeout时间计数器，在接下来一段时间内还可以继续复用。这样无疑省略了反复创建和销毁TCP连接的损耗

------

###  HTTP 1.0，1.1，2.0 的主要区别以及各自的缺点

HTTP1.0：

- 无状态：服务器不跟踪不记录请求过的状态
- 无连接：浏览器每次请求都需要建立tcp连接

HTTP1.1：

- 长连接：新增Connection字段，可以设置keep-alive值保持连接不断开
- 管道化：基于上面长连接的基础，管道化可以不等第一个请求响应继续发送后面的请求，但响应的顺序还是按照请求的顺序返回(*队头阻塞问题*)
- 缓存处理：新增字段cache-control
- 断点传输： 在上传/下载资源时，如果资源过大，将其分割为多个部分，分别上传/下载，如果遇到网络故障，可以从已经上传/下载好的地方继续请求，不用从头开始，提高效率，在 Header 里两个参数实现的，客户端发请求时对应的是 Range 服务器端响应时对应的是 Content-Range

HTTP2.0: 

- 二进制分帧: 将所有传输的信息分割为更小的消息和帧,并对它们采用二进制格式的编码
- 多路复用： 在共享TCP链接的基础上同时发送请求和响应,基于二进制分帧，在同一域名下所有访问都是从同一个tcp连接中走，http消息被分解为独立的帧，乱序发送，服务端根据标识符和首部将消息重新组装起来
- 头部压缩： 使用专门的 HPACK 算法，每次请求和响应只发送差异头部，一般可以达到 50%~90% 的高压缩率
- 服务器推送：服务器可以额外的向客户端推送资源，而无需客户端明确的请求
- 请求优先级：虽然无限的并发流解决了队头阻塞的问题，但如果带宽受限，客户端可能会因防止堵塞通道而阻止请求。在网络通道被非关键资源堵塞时，高优先级的请求会被优先处理

HTTP1.x，HTTP2,都是基于TCP传输协议，需要经过三次握手连接，**连接消耗**，**队头阻塞问题没有彻底解决**

HTTP2,共用同一个TCP连接，如果出现**丢包问题，引发重传**，整个 TCP 都要等待重传，那么就会阻塞该 TCP 连接中的所有请求

HTTP2多路复用容易 Timeout

**思考：能否使用UPD作为传输层协议，UDP作为传输协议，如何保证数据的可靠性？**

------

### HTTP 的方法有哪些

- **GET**: GET方法请求一个指定资源的表示形式. 使用GET的请求应该只被用于获取数据.
- **HEAD**: HEAD方法请求一个与GET请求的响应相同的响应，但没有响应体
- **POST**: POST方法用于将实体提交到指定的资源，通常导致在服务器上的状态变化或副作用
- **DELETE**: DELETE方法删除指定的资源
- **PUT**: PUT方法用请求有效载荷替换目标资源的所有当前表示
- **OPTIONS**: OPTIONS方法用于描述目标资源的通信选项
- **CONNECT**：CONNECT方法建立一个到由目标资源标识的服务器的隧道
- **TRACE**：TRACE方法沿着到目标资源的路径执行一个消息环回测试
- **PATCH**：PATCH方法用于对资源应用部分修改

------

### 什么是中间人攻击？如何防止攻击？

**中间人攻击**：当客户端与服务端通信时，攻击者使用工具或技能让自己处于两个端之间，尽管交谈双方都认为是与对方在通信，但实际上他们是在与攻击者通信

HTTPS只能防止通信过程中不被攻击（攻击很难，成本很高），但是在通信建立的时候中间人会实施攻击

通过**数字签名**，**CA证书**来防止中间人攻击，（但是CA，信任体系的是否真的可信）

------

### WebSocket 是如何进行传输的

- 首先Websocket是基于HTTP协议的，或者说**借用**了HTTP的协议来完成一部分握手
- Websocket是一个**持久化**的协议，相对于HTTP这种**非持久**的协议来说

- WebSocket是一种双向通信协议。在建立连接后，WebSocket服务器端和客户端都能主动向对方发送或接收数据，就像Socket一样；
- WebSocket需要像TCP一样，先建立连接，连接成功后才能相互通信

------

### 从输入 URL 到展现页面的全过程

- DNS解析： 将域名解析为对应的IP地址，DNS存在着多级缓存，从离浏览器的距离排序的话，有以下几种: 浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存
- TCP连接： 三次握手进行连接
- 发送HTTP请求： 请求报文，查询是否有缓存，
- 服务器处理请求并返回HTTP报文
- 浏览器解析渲染页面： DOM，CSS解析，合成图层，GUI渲染
- 连接结束：TCP四次挥手，断开连接

整个过程涉及知识点非常多，此处只做简化讲解